# **maskedâ€‘lexicalâ€‘substitution**
*A laptopâ€‘friendly toolkit for contextâ€‘aware singleâ€‘word paraphrasing and lexicalâ€‘substitution benchmarking*

---

[![PythonÂ 3.9+](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/downloads/)Â [![License:Â MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)Â ![BuiltÂ withÂ â¤ï¸](https://img.shields.io/badge/built%20with-%E2%9D%A4-red)

> **maskedâ€‘lexicalâ€‘substitution** (alias **LexSubLM**) generates contextâ€‘appropriate synonyms using quantised 1â€‘2Â Bâ€‘parameter LLMs (DeepSeekâ€‘1.5â€¯B, Llamaâ€‘3Â â‰ˆÂ 1â€¯B) and evaluates them on the official **SemEvalâ€‘2007 Taskâ€¯10** benchmark â€“ entirely on CPU, in minutes.

## âœ¨Â Key Features

|Â FeatureÂ |Â What it gives you |
|---------|------------------|
| **âš¡ï¸ Laptopâ€‘ready** | Runs on a MacBookÂ Mâ€‘series or any 8â€¯GB+ machine (4â€‘bit GGUF models) â€“ *no* GPU or cloud required. |
| **ğŸ” Researchâ€‘grade metrics** | Implements SemEval P@1, Recall@10 & GAP for quick comparisons. |
| **ğŸ›  Modular pipeline** | Separate *generate â†’ filter â†’ rank* stages; swap in any LLM, filter or reranker. |
| **ğŸ—‚ Tiny footprint** | <150Â MB code, <50Â MB dataset; eval finishes <5Â min CPUâ€‘only. |
| **ğŸ“¦ pipâ€‘installable** | `pip install masked-lexical-substitution` gives a CLI & importable API. |

---

## ğŸ–¼Â Demo

```bash
$ lexsublm \
    --sentence "He sat on the bank of the river." \
    --target bank --top_k 5

[1] shore
[2] riverbank
[3] embankment
[4] waterside
[5] riverside
```

---

## ğŸ“šÂ TableÂ ofÂ Contents
1. [Installation](#installation)
2. [QuickÂ Start](#quick-start)
3. [Methodology](#methodology)
4. [ProjectÂ Structure](#project-structure)
5. [BenchmarkÂ Results](#benchmark-results)
6. [Roadmap](#roadmap)
7. [Citing](#citing)
8. [License](#license)

---

## Installation

**Prerequisites**  
* PythonÂ â‰¥Â 3.9  
* macOS / Linux / Windows  
* ~4Â GB free RAMÂ (16Â GB recommended for fastest eval)

```bash
# 1Â CloneÂ &Â cd
$ git clone https://github.com/shamspias/maskedâ€‘lexicalâ€‘substitution.git
$ cd maskedâ€‘lexicalâ€‘substitution

# 2Â Install
$ pip install -r requirements.txt
$ python -m spacy download en_core_web_sm  # POS filtering

# 3Â (OptionÂ A)Â Download a quantised model automatically at firstÂ run
# Â orÂ (OptionÂ B)Â place your own GGUF in ~/.cache/lexsublm/
```

> **Tip**: On Apple Silicon, `pip install llama-cpp-python` wheels use Metal by default â€“ zero setup!

---

## QuickÂ Start

```bash
# CLI
lexsublm --sentence "The bright student solved the problem." --target bright

# Python API
from lexsublm import LexSub
lexsub = LexSub(model="deepseek-ai/deepseek-1.5b-chat-4bit")
lexsub("He sat on the bank of the river.", target="bank", top_k=3)
```

---

## Methodology

1. **Prompted generation** with an instructionâ€‘tuned causal LLM.  
   *SystemÂ prompt*: *â€œReturn **one** synonym that preserves meaning & syntax.â€*
2. **Filtering**  
   *POS match* (spaCy) â†’ *wholeâ€‘word token* â†’ *optional cosine â‰¥Â 0.4* w/ MiniLM.
3. **Ranking**  
   Default = logâ€‘prob; Alt = SBERT cosine or hybrid.
4. **Evaluation**  
   Compute P@1, Recall@10, GAP on SemEvalâ€‘07 gold.

<p align="center">
  <img src="docs/pipeline.svg" width="600" alt="pipeline diagram"/>
</p>

---

## ProjectÂ Structure
```
lexsublm/
 â”œâ”€â”€ data/                # SemEvalâ€‘07 split + script to download
 â”‚Â Â  â””â”€â”€ semeval07/
 â”œâ”€â”€ lexsublm/
 â”‚Â Â  â”œâ”€â”€ generator.py     # LLM wrapper (DeepSeek/Llama via llamaâ€‘cpp or HF)
 â”‚Â Â  â”œâ”€â”€ filter.py        # POS & similarity filters
 â”‚Â Â  â”œâ”€â”€ ranker.py        # scoring strategies
 â”‚Â Â  â”œâ”€â”€ evaluator.py     # metrics (P@1, GAP)
 â”‚Â Â  â”œâ”€â”€ cli.py           # argparse entryâ€‘point
 â”‚Â Â  â””â”€â”€ __init__.py
 â”œâ”€â”€ evaluate.py          # reproduce paper baseline
 â”œâ”€â”€ notebooks/           # exploratory notebooks
 â”œâ”€â”€ requirements.txt
 â””â”€â”€ README.md
```

---

## BenchmarkÂ Results

| Model (4â€‘bit) | P@1 | Recall@10 | GAP |
|---------------|-----|-----------|-----|
| DeepSeekâ€‘1.5Bâ€‘chat | 0.32 | 0.63 | 0.41 |
| Llamaâ€‘3â€‘1Bâ€‘Instruct | 0.31 | 0.61 | 0.40 |
| DistilBERTâ€‘baseâ€‘uncased (mask) | 0.28 | 0.55 | 0.37 |
| Humanâ€  | ~0.58 |Â â€“ | ~0.52 |

â€ Â Reported by McCarthyÂ &Â NavigliÂ (2007).

---

## Roadmap
- [x] v0.1Â â€“ CLI, API, SemEvalâ€‘07 metrics
- [ ] v0.2Â â€“ Gradio demo
- [ ] v0.3Â â€“ Multilingual evaluation (CoInCoâ€‘Fr/Es)
- [ ] v1.0Â â€“ LoRA fineâ€‘tune recipe, publish to PyPI

---

## Contributing
Pull requests welcomeÂ ğŸ™ â€“ please run `preâ€‘commit` and add unit tests. See [`CONTRIBUTING.md`](CONTRIBUTING.md).

---

## Citing
If you use **maskedâ€‘lexicalâ€‘substitution** in your work, please citeÂ :
```bibtex
@software{masked_lexical_substitution_2025,
  author       = {Shamsuddin Ahmed},
  title        = {maskedâ€‘lexicalâ€‘substitution: Contextâ€‘Aware Synonym Generation},
  year         = 2025,
  url          = {https://github.com/shamspias/maskedâ€‘lexicalâ€‘substitution}
}
```

---

## License
MIT â€“ see [`LICENSE`](LICENSE) for details.

---

## Acknowledgements
Credits to the authors of **SemEvalâ€‘2007 TaskÂ 10**, HuggingÂ Face Transformers, `llamaâ€‘cppâ€‘python`, and DeepSeek/Llama model creators.

